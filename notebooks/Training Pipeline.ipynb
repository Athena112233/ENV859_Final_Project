{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd8591d6",
   "metadata": {},
   "source": [
    "# Blue Rockfish Habitat Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c91335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import pickle\n",
    "import xgboost\n",
    "import torch\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from simpledbf import Dbf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb6baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eval_data(files):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d790d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preprocess_train_data(files):\n",
    "    \"\"\"\n",
    "    description\n",
    "    \n",
    "    param files: \n",
    "    \"\"\"\n",
    "    \n",
    "    # set up env\n",
    "    arcpy.env.workspace = 'data'\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    save_path = '../../scratch/'\n",
    "    \n",
    "    # gather the shape files\n",
    "    files = np.array(files)\n",
    "    obs = files[0]\n",
    "    rnd = files[1]\n",
    "    \n",
    "    # gather the raster files\n",
    "    rasters = files[2:]\n",
    "    rasters = list(rasters[rasters != '#'])\n",
    "\n",
    "    # sample rasters from observed points\n",
    "    obs_table = save_path + 'observed_presence_sampled.shp'\n",
    "    obs_points = arcpy.sa.Sample(rasters, obs, obs_table)\n",
    "    obs_count = int(arcpy.management.GetCount(obs_table)[0])\n",
    "    obs_label = np.array([1]*obs_count)\n",
    "    \n",
    "    # sample rasters from absence points\n",
    "    rnd_table = save_path + 'random_absence_sampled.shp'\n",
    "    rnd_points = arcpy.sa.Sample(rasters, rnd, rnd_table)\n",
    "    rnd_count = int(arcpy.management.GetCount(rnd_table)[0])\n",
    "    rnd_label = np.array([0]*rnd_count)\n",
    "\n",
    "    return obs_table, obs_label, rnd_table, rnd_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a8fdf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(files):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    \n",
    "    param files: \n",
    "    \"\"\"\n",
    "    # preprocess data\n",
    "    obs_path, obs_label, rnd_path, rnd_label = files\n",
    "    \n",
    "    # read training file\n",
    "    obs_dbf = Dbf5(obs_path)\n",
    "    rnd_dbf = Dbf5(rnd_path)\n",
    "    obs_df = obs_dbf.to_dataframe()\n",
    "    rnd_df = rnd_dbf.to_dataframe()\n",
    "\n",
    "    # prepare data for training\n",
    "    obs_df = obs_df.drop(columns = ['brf_obs', 'X', 'Y'])\n",
    "    rnd_df = rnd_df.drop(columns = ['rand_obs', 'X', 'Y'])\n",
    "    obs_df['label'] = obs_label\n",
    "    rnd_df['label'] = rnd_label\n",
    "    data = pd.concat([obs_df, rnd_df])\n",
    "    X = data.drop(columns = ['label'])\n",
    "    Y = data['label']\n",
    "    \n",
    "    # build xgboost model\n",
    "    clf = XGBClassifier(objective= 'binary:logistic')\n",
    "    parameters = {\n",
    "        'max_depth': range (2, 10),\n",
    "        'n_estimators': range(60, 220, 40),\n",
    "        'learning_rate': [0.1, 0.01, 0.05]\n",
    "    }\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator = clf,\n",
    "        param_grid = parameters,\n",
    "        scoring = 'roc_auc',\n",
    "        n_jobs = 5,\n",
    "        cv = 5,\n",
    "        verbose = True)\n",
    "    grid_search.fit(X, Y)\n",
    "    \n",
    "    model_path = \"../../scratch/xgb_model.pkl\"\n",
    "    pickle.dump(grid_search, open(model_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e4908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(files):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    \n",
    "    param files\n",
    "    \"\"\"\n",
    "    files = files[0]\n",
    "    \n",
    "    # process files for prediction\n",
    "    data = preprocess_eval_data(files)\n",
    "    \n",
    "    # read model\n",
    "    model = pickle.load(open('../../scratch/xgb_model.pkl', 'rb'))\n",
    "    \n",
    "    # save raster file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f586e",
   "metadata": {},
   "source": [
    "### Run Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad86da",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_files = []\n",
    "build_model(input_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa6cff9",
   "metadata": {},
   "source": [
    "### Run Testing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e372b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_input_files = []\n",
    "raster = make_prediction(input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a8e70c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
